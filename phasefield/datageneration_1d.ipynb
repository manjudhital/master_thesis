{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'tf' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 65\u001b[0m\n\u001b[0;32m     62\u001b[0m Nu \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m \u001b[38;5;66;03m# number of training data for u (inputs for branch network)\u001b[39;00m\n\u001b[0;32m     63\u001b[0m length_scale \u001b[38;5;241m=\u001b[39m [ \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m1.0\u001b[39m] \u001b[38;5;66;03m# length scale for the kernel\u001b[39;00m\n\u001b[1;32m---> 65\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[43mx_train\u001b[49m\u001b[43m(\u001b[49m\u001b[43mNx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m uk \u001b[38;5;241m=\u001b[39m u_train(X, Nu, length_scale)\n\u001b[0;32m     68\u001b[0m \u001b[38;5;66;03m# Create a dataset object for X_PDE\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[1], line 46\u001b[0m, in \u001b[0;36mx_train\u001b[1;34m(Nx)\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mx_train\u001b[39m(Nx):\n\u001b[0;32m     45\u001b[0m     x \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mlinspace(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m, Nx)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m---> 46\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtf\u001b[49m\u001b[38;5;241m.\u001b[39mconstant(x, dtype\u001b[38;5;241m=\u001b[39mtf\u001b[38;5;241m.\u001b[39mfloat32)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'tf' is not defined"
     ]
    }
   ],
   "source": [
    "import jax.numpy as jnp\n",
    "import numpy as np\n",
    "from jax import random\n",
    "from scipy.spatial.distance import cdist\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import time\n",
    "from scipy import spatial, interpolate\n",
    "\n",
    "# Random Gaussian Process\n",
    "def gaussian_process(x , num_curves, length_scale_list, u_mean=0.):\n",
    "    '''\n",
    "    x -  discretized locations of each curve (numpy array of size N X 1)\n",
    "    num_curves - Number of curves to sample (number of samples)\n",
    "    length_scale_list - List of length scales (standard deviation) to sample from\n",
    "    u_mean - Mean of the Gaussian process\n",
    "    '''\n",
    "    X = np.expand_dims(x, 1)\n",
    "    ys = []\n",
    "    # Draw samples from the prior at our data points.\n",
    "    # Assume a mean of 0 for simplicity\n",
    "    for _ in range(num_curves):\n",
    "        length_scale = np.random.choice(length_scale_list) # Length scale of kernel randomly drawn from a list\n",
    "        # Exponentiated quadratic kernel (or squared exponential, Gaussian, RBF)\n",
    "        cov = np.exp(-0.5 * spatial.distance.cdist(X, X, 'sqeuclidean') / length_scale**2) # Kernel of data points\n",
    "        yst = np.random.multivariate_normal( mean=u_mean * np.ones(len(X)), cov=cov, size=1)\n",
    "        \n",
    "        if len(ys) == 0:\n",
    "            ys = yst\n",
    "        else:\n",
    "            ys = np.vstack((ys, yst))\n",
    "    return ys\n",
    "\n",
    "def normalize(ys):\n",
    "    '''\n",
    "    ys - N X M matrix of M curves with N points each\n",
    "    Normalize the data to be between -1 and 1\n",
    "    '''\n",
    "    if (np.max(np.abs(ys)) > 1):\n",
    "        ys = np.divide(ys, np.reshape(np.max(np.abs(ys), 1), (-1,1)) )\n",
    "    return ys\n",
    "\n",
    "# Training data for x\n",
    "def x_train(Nx):\n",
    "    x = np.linspace(-1, 1, Nx).reshape(-1, 1)\n",
    "    return jnp.array(x, dtype=jnp.float32)\n",
    "\n",
    "# Training data for u_k\n",
    "def u_train(x, Nu, length_scale_list, u_mean=0.):\n",
    "    x = x[:,0].numpy()\n",
    "    u = gaussian_process(x, Nu, length_scale_list, u_mean)\n",
    "    u = 0.8*u*(x+1.)*(x-1.)\n",
    "    #u = normalize(u)\n",
    "    # matrix of sign of u\n",
    "    u = np.exp(1.5*(1 - np.abs(u))) * u\n",
    "    return jnp.array(u, dtype=jnp.float32)\n",
    "\n",
    "\n",
    "\n",
    "# Step 3.0 Generate training data\n",
    "Nx = 100  # number of training data for x (discreted locations along x-axis)\n",
    "Nu = 2000 # number of training data for u (inputs for branch network)\n",
    "length_scale = [ 0.5, 1.0] # length scale for the kernel\n",
    "\n",
    "X = x_train(Nx)\n",
    "uk = u_train(X, Nu, length_scale)\n",
    "\n",
    "# Create a dataset object for X_PDE\n",
    "u_train_dataset = jnp.data.Dataset.from_tensor_slices((X, uk))\n",
    "# Shuffle and batch data\n",
    "u_train_dataset = u_train_dataset.shuffle(buffer_size=Nu).batch(256)\n",
    "\n",
    "\n",
    "\n",
    "# sample 20 points out of 100 for each curve in uk\n",
    "uk_sampled = uk[:,::5]\n",
    "uk_sampled_train_dataset = jnp.data.Dataset.from_tensor_slices((uk_sampled, uk))\n",
    "uk_sampled_train_dataset = uk_sampled_train_dataset.shuffle(buffer_size=Nu).batch(256)\n",
    "\n",
    "\n",
    "for i in range(10):\n",
    "    plt.plot(X[:,0],uk[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
